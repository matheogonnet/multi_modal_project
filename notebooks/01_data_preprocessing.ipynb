{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Notebook 1 : Prétraitement des Données**\n",
    "\n",
    "Dans ce notebook, nous préparons les données nécessaires pour l'entraînement des modèles de deep learning. Les principales étapes effectuées sont :\n",
    "\n",
    "- **Chargement des Données :** Nous importons les images et les légendes associées depuis le jeu de données **Flickr8k**.\n",
    "- **Sélection d'un Sous-ensemble d'Images :** Nous limitons le jeu de données à **5000 images** pour réduire la complexité computationnelle et faciliter l'entraînement du modèle.\n",
    "- **Tokenisation du Texte :** Nous convertissons les légendes en séquences numériques en utilisant un tokenizer. Chaque mot est remplacé par son index dans le vocabulaire.\n",
    "- **Limitation du Vocabulaire :** Nous limitons le vocabulaire aux mots les plus fréquents pour réduire la complexité et améliorer l'efficacité du modèle.\n",
    "- **Padding des Séquences :** Les séquences sont paddées à une longueur fixe (`MAX_SEQUENCE_LENGTH = 30`) pour assurer une cohérence dans les dimensions des entrées du modèle.\n",
    "- **Encodage des Labels :** Nous créons des vecteurs de labels pour une classification **multi-label**, où chaque image peut appartenir à plusieurs classes simultanément.\n",
    "- **Sauvegarde des Données Prétraitées :** Nous sauvegardons les données prétraitées (images, séquences, labels) pour les utiliser dans les notebooks suivants.\n",
    "\n",
    "**Pourquoi ?**\n",
    "\n",
    "Un prétraitement adéquat des données est essentiel pour préparer les images et les textes dans un format compatible avec les modèles de deep learning. En limitant le nombre d'images à **5000**, nous réduisons la charge computationnelle et accélérons le temps d'entraînement, tout en conservant une quantité suffisante de données pour que le modèle puisse apprendre efficacement. Cela permet d'assurer que les modèles peuvent apprendre efficacement à partir des données, en réduisant les problèmes liés à la variabilité des entrées.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des bibliothèques nécessaires\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aperçu des données brutes :\n",
      "                       image  \\\n",
      "0  1000268201_693b08cb0e.jpg   \n",
      "1  1000268201_693b08cb0e.jpg   \n",
      "2  1000268201_693b08cb0e.jpg   \n",
      "3  1000268201_693b08cb0e.jpg   \n",
      "4  1000268201_693b08cb0e.jpg   \n",
      "\n",
      "                                             caption  \n",
      "0  A child in a pink dress is climbing up a set o...  \n",
      "1              A girl going into a wooden building .  \n",
      "2   A little girl climbing into a wooden playhouse .  \n",
      "3  A little girl climbing the stairs to her playh...  \n",
      "4  A little girl in a pink dress going into a woo...  \n",
      "Nombre total de légendes : 40455\n"
     ]
    }
   ],
   "source": [
    "# Chemins des données\n",
    "data_dir = \"../datasets/flickr8k/\" \n",
    "images_dir = os.path.join(data_dir, \"images/\") \n",
    "captions_file = os.path.join(data_dir, \"captions.txt\")\n",
    "\n",
    "# Charger les légendes depuis captions.txt en prenant en compte l'en-tête\n",
    "captions_df = pd.read_csv(captions_file, sep=\",\", header=0, names=[\"image\", \"caption\"]) \n",
    "\n",
    "# Afficher les premières lignes\n",
    "print(\"Aperçu des données brutes :\")\n",
    "print(captions_df.head())\n",
    "print(f\"Nombre total de légendes : {len(captions_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aperçu des légendes nettoyées :\n",
      "                       image  \\\n",
      "0  1000268201_693b08cb0e.jpg   \n",
      "1  1000268201_693b08cb0e.jpg   \n",
      "2  1000268201_693b08cb0e.jpg   \n",
      "3  1000268201_693b08cb0e.jpg   \n",
      "4  1000268201_693b08cb0e.jpg   \n",
      "\n",
      "                                     cleaned_caption  \n",
      "0  a child in a pink dress is climbing up a set o...  \n",
      "1               a girl going into a wooden building   \n",
      "2    a little girl climbing into a wooden playhouse   \n",
      "3  a little girl climbing the stairs to her playh...  \n",
      "4  a little girl in a pink dress going into a woo...  \n"
     ]
    }
   ],
   "source": [
    "# Fonction pour nettoyer le texte\n",
    "def clean_caption(caption):\n",
    "    caption = caption.lower()  # Mettre en minuscule\n",
    "    caption = re.sub(r\"[^a-z0-9 ]\", \"\", caption)  # Retirer les caractères spéciaux\n",
    "    return caption\n",
    "\n",
    "# Appliquer le nettoyage sur les légendes\n",
    "captions_df[\"cleaned_caption\"] = captions_df[\"caption\"].apply(clean_caption)\n",
    "\n",
    "print(\"Aperçu des légendes nettoyées :\")\n",
    "print(captions_df[[\"image\", \"cleaned_caption\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 mots les plus fréquents comme classes :\n",
      "['a', 'in', 'the', 'on', 'is', 'and', 'dog', 'with', 'man', 'of', 'two', 'white', 'black', 'boy', 'are', 'woman', 'girl', 'to', 'wearing', 'at', 'people', 'water', 'red', 'young', 'brown', 'an', 'his', 'blue', 'dogs', 'running', 'through', 'playing', 'while', 'down', 'shirt', 'standing', 'ball', 'little', 'grass', 'child', 'person', 'snow', 'jumping', 'over', 'front', 'three', 'sitting', 'holding', 'field', 'small']\n"
     ]
    }
   ],
   "source": [
    "# Extraire tous les mots des légendes\n",
    "all_captions = ' '.join(captions_df[\"cleaned_caption\"]).split()\n",
    "word_counts = Counter(all_captions)\n",
    "\n",
    "# Définir le nombre de classes \n",
    "NUM_CLASSES = 50 # On prend 50 car cela nous permettra de réduire la taille du vocabulaire et donc accélérer l'entraînement\n",
    "common_words = [word for word, count in word_counts.most_common(NUM_CLASSES)]\n",
    "\n",
    "print(f\"Top {NUM_CLASSES} mots les plus fréquents comme classes :\")\n",
    "print(common_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'images uniques après limitation :\n",
      "8091\n",
      "Aperçu des étiquettes de classe assignées :\n",
      "                       image  \\\n",
      "0  1000268201_693b08cb0e.jpg   \n",
      "1  1001773457_577c3a7d70.jpg   \n",
      "2  1002674143_1b742ab4b8.jpg   \n",
      "3  1003163366_44323f5815.jpg   \n",
      "4  1007129816_e794419615.jpg   \n",
      "\n",
      "                                             classes  \n",
      "0                [0, 1, 2, 4, 37, 39, 9, 16, 17, 25]  \n",
      "1  [0, 1, 2, 3, 5, 6, 7, 9, 10, 11, 12, 14, 19, 2...  \n",
      "2  [0, 1, 2, 3, 4, 37, 38, 7, 9, 11, 44, 46, 16, ...  \n",
      "3  [0, 32, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 46, 47...  \n",
      "4                  [0, 1, 2, 4, 5, 7, 8, 18, 19, 25]  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathe\\AppData\\Local\\Temp\\ipykernel_14320\\3283940768.py:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  class_labels = limited_captions_df.groupby(\"image\").apply(assign_classes, common_words=common_words).reset_index(name='classes')\n"
     ]
    }
   ],
   "source": [
    "# Fonction pour assigner des classes à une image en fonction de ses légendes\n",
    "def assign_classes(group, common_words):\n",
    "    captions = group[\"cleaned_caption\"].tolist()\n",
    "    classes = set()\n",
    "    for caption in captions:\n",
    "        words = caption.split()\n",
    "        for word in words:\n",
    "            if word in common_words:\n",
    "                classes.add(common_words.index(word))  # Utiliser l'index comme label\n",
    "    return list(classes)\n",
    "\n",
    "# Limiter les légendes à 5 par image\n",
    "limited_captions_df = captions_df.groupby(\"image\").head(5).reset_index(drop=True)\n",
    "\n",
    "print(\"Nombre d'images uniques après limitation :\")\n",
    "print(len(limited_captions_df[\"image\"].unique()))\n",
    "\n",
    "# Assignation des classes\n",
    "class_labels = limited_captions_df.groupby(\"image\").apply(assign_classes, common_words=common_words).reset_index(name='classes')\n",
    "\n",
    "print(\"Aperçu des étiquettes de classe assignées :\")\n",
    "print(class_labels.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aperçu des séquences de légendes :\n",
      "                       image  \\\n",
      "0  1000268201_693b08cb0e.jpg   \n",
      "1  1000268201_693b08cb0e.jpg   \n",
      "2  1000268201_693b08cb0e.jpg   \n",
      "3  1000268201_693b08cb0e.jpg   \n",
      "4  1000268201_693b08cb0e.jpg   \n",
      "\n",
      "                                     padded_sequence  \n",
      "0  [2, 41, 3, 2, 89, 169, 6, 118, 52, 2, 394, 11,...  \n",
      "1  [2, 18, 313, 63, 2, 193, 116, 0, 0, 0, 0, 0, 0...  \n",
      "2  [2, 39, 18, 118, 63, 2, 193, 2430, 0, 0, 0, 0,...  \n",
      "3  [2, 39, 18, 118, 4, 391, 19, 59, 2430, 0, 0, 0...  \n",
      "4  [2, 39, 18, 3, 2, 89, 169, 313, 63, 2, 193, 29...  \n"
     ]
    }
   ],
   "source": [
    "# Initialiser le tokenizer\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token=\"<unk>\")\n",
    "tokenizer.fit_on_texts(limited_captions_df[\"cleaned_caption\"])\n",
    "\n",
    "# Convertir les légendes en séquences d'indices\n",
    "limited_captions_df[\"caption_sequence\"] = tokenizer.texts_to_sequences(\n",
    "    limited_captions_df[\"cleaned_caption\"]\n",
    ")\n",
    "\n",
    "# Padding des séquences\n",
    "max_caption_length = 30\n",
    "limited_captions_df[\"padded_sequence\"] = pad_sequences(\n",
    "    limited_captions_df[\"caption_sequence\"], maxlen=max_caption_length, padding=\"post\"\n",
    ").tolist()\n",
    "\n",
    "print(\"Aperçu des séquences de légendes :\")\n",
    "print(limited_captions_df[[\"image\", \"padded_sequence\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'images uniques dans l'ensemble d'entraînement : 4000\n",
      "Nombre total d'exemples dans l'ensemble d'entraînement : 20000\n",
      "Nombre d'images uniques dans l'ensemble de test : 1000\n",
      "Nombre total d'exemples dans l'ensemble de test : 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathe\\AppData\\Local\\Temp\\ipykernel_14320\\3640787893.py:14: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_data = filtered_grouped_captions.groupby(\"image\").apply(\n"
     ]
    }
   ],
   "source": [
    "# Sélectionner 800 images uniques\n",
    "sampled_images = limited_captions_df[\"image\"].unique()[:5000]\n",
    "\n",
    "# Filtrer les légendes pour ne garder que celles des 800 images sélectionnées\n",
    "sampled_captions_df = limited_captions_df[limited_captions_df[\"image\"].isin(sampled_images)]\n",
    "\n",
    "# Vérifier que chaque image a exactement 5 légendes associées\n",
    "filtered_grouped_captions = sampled_captions_df.groupby(\"image\").filter(lambda group: len(group) == 5).reset_index(drop=True)\n",
    "\n",
    "# Obtenir les classes assignées\n",
    "assigned_classes = class_labels[class_labels['image'].isin(sampled_images)]\n",
    "\n",
    "# Grouper les données par image\n",
    "grouped_data = filtered_grouped_captions.groupby(\"image\").apply(\n",
    "    lambda group: [(os.path.join(images_dir, row[\"image\"]), row[\"padded_sequence\"], assigned_classes[assigned_classes[\"image\"] == row[\"image\"]][\"classes\"].values[0]) for _, row in group.iterrows()]\n",
    ").tolist()\n",
    "\n",
    "# Diviser les images en train/test\n",
    "train_groups, test_groups = train_test_split(grouped_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reconstituer les données\n",
    "train_data = [item for group in train_groups for item in group]\n",
    "test_data = [item for group in test_groups for item in group]\n",
    "\n",
    "print(f\"Nombre d'images uniques dans l'ensemble d'entraînement : {len(train_groups)}\")\n",
    "print(f\"Nombre total d'exemples dans l'ensemble d'entraînement : {len(train_data)}\")\n",
    "print(f\"Nombre d'images uniques dans l'ensemble de test : {len(test_groups)}\")\n",
    "print(f\"Nombre total d'exemples dans l'ensemble de test : {len(test_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données prétraitées sauvegardées.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Fonction pour convertir les classes en vecteurs multi-label\n",
    "def multi_label_encode(classes, num_classes):\n",
    "    label = np.zeros(num_classes)\n",
    "    for cls in classes:\n",
    "        label[cls] = 1\n",
    "    return label\n",
    "\n",
    "# Appliquer l'encodage multi-label\n",
    "train_data_encoded = [(img, seq, multi_label_encode(cls, NUM_CLASSES)) for img, seq, cls in train_data]\n",
    "test_data_encoded = [(img, seq, multi_label_encode(cls, NUM_CLASSES)) for img, seq, cls in test_data]\n",
    "\n",
    "# Sauvegarder les données\n",
    "with open(os.path.join(data_dir, \"train_data.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(train_data_encoded, f)\n",
    "\n",
    "with open(os.path.join(data_dir, \"test_data.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(test_data_encoded, f)\n",
    "\n",
    "# Enregistrer le tokenizer et les classes\n",
    "with open(os.path.join(data_dir, \"tokenizer.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "\n",
    "with open(os.path.join(data_dir, \"class_labels.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(common_words, f)\n",
    "\n",
    "print(\"Données prétraitées sauvegardées.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
