{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Résumé des étapes dans ce notebook 01 :\n",
    "- Chargement des données (images et légendes).\n",
    "- Prétraitement des images (redimensionner, normaliser).\n",
    "- Prétraitement des légendes (nettoyage, tokenisation, padding).\n",
    "- Association des images et des légendes.\n",
    "- Division en ensembles d’entraînement et de test.\n",
    "- Sauvegarde des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les bibliothèques\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aperçu des données brutes :\n",
      "                       image  \\\n",
      "0                      image   \n",
      "1  1000268201_693b08cb0e.jpg   \n",
      "2  1000268201_693b08cb0e.jpg   \n",
      "3  1000268201_693b08cb0e.jpg   \n",
      "4  1000268201_693b08cb0e.jpg   \n",
      "\n",
      "                                             caption  \n",
      "0                                            caption  \n",
      "1  A child in a pink dress is climbing up a set o...  \n",
      "2              A girl going into a wooden building .  \n",
      "3   A little girl climbing into a wooden playhouse .  \n",
      "4  A little girl climbing the stairs to her playh...  \n",
      "Nombre total de légendes : 40456\n"
     ]
    }
   ],
   "source": [
    "# Chemins des données\n",
    "data_dir = \"../datasets/flickr8k/\"\n",
    "images_dir = os.path.join(data_dir, \"images/\")\n",
    "captions_file = os.path.join(data_dir, \"captions.txt\")\n",
    "\n",
    "# Charger le fichier captions.txt\n",
    "captions_df = pd.read_csv(captions_file, sep=\",\", header=None, names=[\"image\", \"caption\"])\n",
    "\n",
    "# Aperçu des données brutes\n",
    "print(\"Aperçu des données brutes :\")\n",
    "print(captions_df.head())\n",
    "print(f\"Nombre total de légendes : {len(captions_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'images valides : 8091\n",
      "Nombre d'images invalides : 1\n",
      "Nombre de légendes après validation des images : 40455\n"
     ]
    }
   ],
   "source": [
    "# Vérifier que les fichiers d'images existent\n",
    "def validate_image_paths(captions_df, images_dir):\n",
    "    valid_images = []\n",
    "    invalid_images = []\n",
    "\n",
    "    for image in captions_df[\"image\"].unique():\n",
    "        image_path = os.path.join(images_dir, image)\n",
    "        if os.path.exists(image_path):\n",
    "            valid_images.append(image)\n",
    "        else:\n",
    "            invalid_images.append(image)\n",
    "\n",
    "    print(f\"Nombre d'images valides : {len(valid_images)}\")\n",
    "    print(f\"Nombre d'images invalides : {len(invalid_images)}\")\n",
    "    return valid_images\n",
    "\n",
    "valid_images = validate_image_paths(captions_df, images_dir)\n",
    "\n",
    "# Garder uniquement les légendes associées aux images valides\n",
    "captions_df = captions_df[captions_df[\"image\"].isin(valid_images)].reset_index(drop=True)\n",
    "print(f\"Nombre de légendes après validation des images : {len(captions_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aperçu des données uniques :\n",
      "                       image  \\\n",
      "0  1000268201_693b08cb0e.jpg   \n",
      "1  1001773457_577c3a7d70.jpg   \n",
      "2  1002674143_1b742ab4b8.jpg   \n",
      "3  1003163366_44323f5815.jpg   \n",
      "4  1007129816_e794419615.jpg   \n",
      "\n",
      "                                             caption  \n",
      "0  A child in a pink dress is climbing up a set o...  \n",
      "1         A black dog and a spotted dog are fighting  \n",
      "2  A little girl covered in paint sits in front o...  \n",
      "3  A man lays on a bench while his dog sits by him .  \n",
      "4     A man in an orange hat starring at something .  \n",
      "Nombre total d'images uniques : 8091\n"
     ]
    }
   ],
   "source": [
    "# Garder une seule légende par image (par exemple, la première)\n",
    "unique_captions_df = captions_df.groupby(\"image\").first().reset_index()\n",
    "\n",
    "print(\"Aperçu des données uniques :\")\n",
    "print(unique_captions_df.head())\n",
    "print(f\"Nombre total d'images uniques : {len(unique_captions_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aperçu des légendes nettoyées :\n",
      "                       image  \\\n",
      "0  1000268201_693b08cb0e.jpg   \n",
      "1  1001773457_577c3a7d70.jpg   \n",
      "2  1002674143_1b742ab4b8.jpg   \n",
      "3  1003163366_44323f5815.jpg   \n",
      "4  1007129816_e794419615.jpg   \n",
      "\n",
      "                                     cleaned_caption  \n",
      "0  a child in a pink dress is climbing up a set o...  \n",
      "1         a black dog and a spotted dog are fighting  \n",
      "2  a little girl covered in paint sits in front o...  \n",
      "3   a man lays on a bench while his dog sits by him   \n",
      "4      a man in an orange hat starring at something   \n"
     ]
    }
   ],
   "source": [
    "# Fonction pour nettoyer le texte\n",
    "def clean_caption(caption):\n",
    "    caption = caption.lower()  # Mettre en minuscule\n",
    "    caption = re.sub(r\"[^a-z0-9 ]\", \"\", caption)  # Retirer les caractères spéciaux\n",
    "    return caption\n",
    "\n",
    "# Appliquer le nettoyage sur les légendes\n",
    "unique_captions_df[\"cleaned_caption\"] = unique_captions_df[\"caption\"].apply(clean_caption)\n",
    "\n",
    "print(\"Aperçu des légendes nettoyées :\")\n",
    "print(unique_captions_df[[\"image\", \"cleaned_caption\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aperçu des séquences de légendes :\n",
      "                       image  \\\n",
      "0  1000268201_693b08cb0e.jpg   \n",
      "1  1001773457_577c3a7d70.jpg   \n",
      "2  1002674143_1b742ab4b8.jpg   \n",
      "3  1003163366_44323f5815.jpg   \n",
      "4  1007129816_e794419615.jpg   \n",
      "\n",
      "                                     padded_sequence  \n",
      "0  [2, 38, 3, 2, 66, 144, 7, 124, 52, 2, 407, 9, ...  \n",
      "1  [2, 12, 8, 5, 2, 754, 8, 17, 369, 0, 0, 0, 0, ...  \n",
      "2  [2, 48, 15, 171, 3, 585, 101, 3, 41, 9, 2, 552...  \n",
      "3  [2, 10, 622, 6, 2, 151, 27, 23, 8, 101, 46, 11...  \n",
      "4  [2, 10, 3, 24, 82, 96, 1203, 19, 163, 0, 0, 0,...  \n"
     ]
    }
   ],
   "source": [
    "# Initialiser le tokenizer\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token=\"<unk>\")\n",
    "tokenizer.fit_on_texts(unique_captions_df[\"cleaned_caption\"])\n",
    "\n",
    "# Convertir les légendes en séquences\n",
    "unique_captions_df[\"caption_sequence\"] = tokenizer.texts_to_sequences(unique_captions_df[\"cleaned_caption\"])\n",
    "\n",
    "# Padding des séquences\n",
    "max_caption_length = 30\n",
    "unique_captions_df[\"padded_sequence\"] = pad_sequences(\n",
    "    unique_captions_df[\"caption_sequence\"], maxlen=max_caption_length, padding=\"post\"\n",
    ").tolist()\n",
    "\n",
    "print(\"Aperçu des séquences de légendes :\")\n",
    "print(unique_captions_df[[\"image\", \"padded_sequence\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'images dans l'ensemble d'entraînement : 6472\n",
      "Nombre d'images dans l'ensemble de test : 1619\n"
     ]
    }
   ],
   "source": [
    "# Diviser les données en train/test\n",
    "train_df, test_df = train_test_split(unique_captions_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Créer les ensembles de données sous forme de tuples (chemin_image, légende_paddée)\n",
    "train_data = [\n",
    "    (os.path.join(images_dir, row[\"image\"]), row[\"padded_sequence\"]) for _, row in train_df.iterrows()\n",
    "]\n",
    "test_data = [\n",
    "    (os.path.join(images_dir, row[\"image\"]), row[\"padded_sequence\"]) for _, row in test_df.iterrows()\n",
    "]\n",
    "\n",
    "print(f\"Nombre d'images dans l'ensemble d'entraînement : {len(train_data)}\")\n",
    "print(f\"Nombre d'images dans l'ensemble de test : {len(test_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données prétraitées sauvegardées dans train_data.pkl et test_data.pkl.\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarder les données d'entraînement et de test\n",
    "with open(\"../datasets/flickr8k/train_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(train_data, f)\n",
    "\n",
    "with open(\"../datasets/flickr8k/test_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(test_data, f)\n",
    "\n",
    "print(\"Données prétraitées sauvegardées dans train_data.pkl et test_data.pkl.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
